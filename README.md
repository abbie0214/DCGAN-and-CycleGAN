# DCGAN-and-CycleGAN

This project consists of two parts: in the first part, we will implement a specific type of GAN designed to process images, called a Deep Convolutional GAN (DCGAN) [1]. We will train the DCGAN to generate
emojis from samples of random noise. In the second part, we will implement a more complex GAN architecture called CycleGAN [2], which was designed for the task of image-to-image translation. We will train the CycleGAN to convert between Apple-style and Windows-style emojis. In both parts, you will gain ex-
perience implementing GANs by writing code for the generator, discriminator, and the training loop, for each model.

[1] Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.
[2] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. arXiv preprint, 2017.

